{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Team Members:\n","- Sanchay Gurung\n","- Phongsiri Nirachornkul"],"metadata":{"id":"hN9r1euT_WYd"}},{"cell_type":"markdown","source":["# Installing python-docx library for reading docx file"],"metadata":{"id":"dYSS8VHmlNXO"}},{"cell_type":"code","source":["!pip install python-docx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXfnQCutD-Ac","outputId":"34cd845e-63c8-4445-9470-5df271734301","executionInfo":{"status":"ok","timestamp":1664039386617,"user_tz":300,"elapsed":3261,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.7/dist-packages (0.8.11)\n","Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.9.1)\n"]}]},{"cell_type":"markdown","source":["# Importing libraries for the project"],"metadata":{"id":"l0Gnb0Jhlbd5"}},{"cell_type":"code","source":["import docx\n","import nltk\n","import random\n","from operator import itemgetter\n","from nltk.util import ngrams"],"metadata":{"id":"O1jI48JHIy0d","executionInfo":{"status":"ok","timestamp":1664039386617,"user_tz":300,"elapsed":5,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# Reading docx file\n","The following function `getText(filename)` reads the docx file."],"metadata":{"id":"QxklpAPFlwSi"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_6NVtK7DImo","executionInfo":{"status":"ok","timestamp":1664039387293,"user_tz":300,"elapsed":680,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}},"outputId":"4e821dab-e8c8-4de3-ab78-d88d6fa78a49"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/Othercomputers/My Laptop/UNT/Fall 2022/5290 NLP/Assingment/02"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IrSa5PtC5T0","executionInfo":{"status":"ok","timestamp":1664039387293,"user_tz":300,"elapsed":4,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}},"outputId":"72ee18d3-733b-4d40-a76c-5fbc7bf9c804"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/My Laptop/UNT/Fall 2022/5290 NLP/Assingment/02\n"]}]},{"cell_type":"code","source":["def getText(filename):\n","    doc = docx.Document(filename)\n","    fullText = []\n","    for para in doc.paragraphs:\n","        fullText.append(para.text)\n","    return '\\n'.join(fullText)\n","doc_text = getText(\"5 papers related to blockchain.docx\")   # call the getText() function and assign the read text to variable"],"metadata":{"id":"EEVw-ewsFKLB","executionInfo":{"status":"ok","timestamp":1664040974650,"user_tz":300,"elapsed":96,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["# Tokenization"],"metadata":{"id":"A2aM575pmco_"}},{"cell_type":"code","source":["tokens_document = doc_text.split() # split the document text to tokens\n","token_length_of_document = len(tokens_document)   # total number of token\n","token_length_of_document"],"metadata":{"id":"i6-x9DFUH_OS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5184918-bee1-40c7-865c-f6b710f1f118","executionInfo":{"status":"ok","timestamp":1664039387449,"user_tz":300,"elapsed":7,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9835"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["# Cumulative Probabilaty of Tokens from Frequency Distribution"],"metadata":{"id":"rYV2yohJGOSS"}},{"cell_type":"code","source":["# this function calculates the cumulative probability from the frequency distribution\n","def calculate_cumulative_probability(freq_dist):\n","  token_length = sum(freq_dist.values())      # calculates the number of token length of the received freq_dist\n","  probs = {k: v/token_length for (k,v) in freq_dist.items()}\n","  pvals = list(probs.values())\n","  return {k: sum(pvals[0:ix+1]) for ix, (k,v) in enumerate(probs.items())}"],"metadata":{"id":"iJcMy5YK_K-6","executionInfo":{"status":"ok","timestamp":1664041690433,"user_tz":300,"elapsed":1,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":["# Unigram"],"metadata":{"id":"IkG5gg-FGkvr"}},{"cell_type":"code","source":["freq_dist_doc = nltk.FreqDist(tokens_document)   # unigram frequency distribution"],"metadata":{"id":"tAV05JjhJ2PA","executionInfo":{"status":"ok","timestamp":1664039487292,"user_tz":300,"elapsed":97,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# this function returns a random unigram from tokens of word \n","def get_word_from_unigram(freq_dist):\n","  cumprobs = calculate_cumulative_probability(freq_dist)\n","  keys = list(cumprobs.keys())\n","  values = cumprobs.values()\n","  # rn = random.choice(list(values))\n","  rn = random.random()\n","  ix = [i for (i, v) in enumerate(values) if v > rn][0]\n","  return keys[ix]"],"metadata":{"id":"D5dy8PIaGmpk","executionInfo":{"status":"ok","timestamp":1664041772402,"user_tz":300,"elapsed":89,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["# Generating 5 unigram sentences of 10 words each\n","print(\"Unigram sentences: \")\n","sentence = []\n","for i in range(1,6):\n","  for j in range(10):\n","    sentence.append(get_word_from_unigram(freq_dist_doc))\n","  unigram_sentence = ' '.join(map(str, sentence))\n","  print(f'Sentence {i} : {unigram_sentence}')       #output\n","  sentence = []"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVyS6lU__fC1","outputId":"a8f85999-f2bc-4265-f479-3d2350153a10","executionInfo":{"status":"ok","timestamp":1664042693709,"user_tz":300,"elapsed":1733,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["Unigram sentences: \n","Sentence 1 : inspire and a perform principle the certifying formulated blinded contract\n","Sentence 2 : must which line and their games), be: and token and\n","Sentence 3 : the Introduction Solidity ensure Besides Security if 1) of on\n","Sentence 4 : the such architecture financial improve we controlled. and solving implement\n","Sentence 5 : Before several and deployments simplify which in to way we\n"]}]},{"cell_type":"markdown","source":["# Bigram"],"metadata":{"id":"aO-Cql1-mpf9"}},{"cell_type":"code","source":["cfd_bigram = nltk.ConditionalFreqDist(nltk.bigrams(tokens_document))   # bigram frequency distribution of original document tokens\n","# for item in cfd_bigram.items():\n","#   print(item)\n","# cfd_bigram['a']"],"metadata":{"id":"zdaVyXyYIp2n","executionInfo":{"status":"ok","timestamp":1664042186859,"user_tz":300,"elapsed":240,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["# this function gets a word in parameter and search and returns next word from bigram\n","def get_word_from_bigram(initial_word):\n","  freq_dist_bigram_tuple = cfd_bigram[initial_word]     # get the bigram tuple of the predecessor_word    \n","  next_word = get_word_from_unigram(freq_dist_bigram_tuple)  # get a word from frequency distribution of bigram tuple (bigram tuple is like a unigram)\n","  return next_word"],"metadata":{"id":"rY7y-MgVayNd","executionInfo":{"status":"ok","timestamp":1664042187991,"user_tz":300,"elapsed":89,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["# Generating 5 bigram sentences of 10 words each\n","print(\"Bigram sentences: \")\n","for i in range(1,6):\n","  first_word = get_word_from_unigram(freq_dist_doc)   # get first word from initial document distribution (unigram)\n","  sentence.append(first_word)\n","  for j in range(9):      # iterate 9 times for rest words\n","    next_word = get_word_from_bigram(first_word)\n","    sentence.append(next_word)\n","    first_word = next_word                              # update first_word with next_word for the next iteration\n","  bigram_sentence = ' '.join(map(str, sentence))       #join the words with the whitespace\n","  print(f'Sentence {i} : {bigram_sentence}')           #output\n","  sentence = [] #reset the sentence"],"metadata":{"id":"5Ssn0OtNC1rN","executionInfo":{"status":"ok","timestamp":1664042609255,"user_tz":300,"elapsed":438,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cad15cd8-288d-4a5a-81db-f22cec96903d"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["Bigram sentences: \n","Sentence 1 : can realize data and security and access and characterization of\n","Sentence 2 : respectively 47.398 contracts, and reduce adverse selection and developed; although\n","Sentence 3 : dangers such as an architecture is the data tampering after\n","Sentence 4 : the verified can choose the core of different aspects such\n","Sentence 5 : user education department. The chosen approach [10] consists of different\n"]}]},{"cell_type":"markdown","source":["# Trigram"],"metadata":{"id":"NZbxb1synDUK"}},{"cell_type":"code","source":["trigrams = nltk.trigrams(tokens_document)   # trigram from original document tokens\n","# trigrams=ngrams(tokens,3)\n","condition_pairs = (((w0, w1), w2) for w0, w1, w2 in trigrams)     # conditional pairing for the trigram\n","cfd_trigram = nltk.ConditionalFreqDist(condition_pairs)         # trigram frequency distribution of the trigram"],"metadata":{"id":"eVz_l_JqVJ-g","executionInfo":{"status":"ok","timestamp":1664042867845,"user_tz":300,"elapsed":114,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["# this function gets two words (bigram) in parameter and search and returns third word from trigram\n","def get_word_from_trigram(first_word, second_word):\n","  freq_dist_trigram_tuple = cfd_trigram[(first_word, second_word)]     # get the trigram tuple from the bigram word\n","  next_word = get_word_from_unigram(freq_dist_trigram_tuple)  # get a word from frequency distribution of trigram tuple (trigram tuple is like a unigram)\n","  return next_word"],"metadata":{"id":"gE2SGkmVeIrW","executionInfo":{"status":"ok","timestamp":1664042868569,"user_tz":300,"elapsed":102,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["# Generating 5 trigram sentences of 10 words each\n","print(\"Trigram sentences: \")\n","for i in range(1,6):\n","  first_word = get_word_from_unigram(freq_dist_doc)   # get first word from initial document distribution (unigram)\n","  sentence.append(first_word)\n","  second_word = get_word_from_bigram(first_word)\n","  sentence.append(second_word)\n","  for j in range(8):      # iterate 8 times for rest words\n","    next_word = get_word_from_trigram(first_word, second_word)\n","    sentence.append(next_word)\n","    first_word = second_word    # update first_word with second_word for the next iteration        \n","    second_word = next_word    # update second_word with next_word for the next iteration    \n","  trigrams_sentence = ' '.join(map(str, sentence))       #join the words with the whitespace\n","  print(f'Sentence {i} : {trigrams_sentence}') \n","  sentence = []"],"metadata":{"id":"7FadCpPkW63h","executionInfo":{"status":"ok","timestamp":1664042915186,"user_tz":300,"elapsed":296,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5e7c446-4508-4a72-f0cc-86bba94934f9"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["Trigram sentences: \n","Sentence 1 : new operation plan for the commanding heights of blockchain technology.\n","Sentence 2 : many are publicly unavailable, thus it is capable of deploying\n","Sentence 3 : evaluating the behaviour of blockchain digital finance, supply chain management,\n","Sentence 4 : contracts. In particular, we used unsupervised learning techniques. The chosen\n","Sentence 5 : of n number of topics by evaluating the behaviour of\n"]}]},{"cell_type":"markdown","source":["# Four-grams"],"metadata":{"id":"KnVe3rpPnKi8"}},{"cell_type":"code","source":["fourgrams=ngrams(tokens_document,4)     # generate fourgram from original document tokens\n","condition_pairs = (((w0, w1, w2), w3) for w0, w1, w2, w3 in fourgrams)    # conditional pairing for the fourgram\n","cfd_fourgram = nltk.ConditionalFreqDist(condition_pairs)     # conditional frequency distribution of the trigram"],"metadata":{"id":"A2KlXaKlD_dc","executionInfo":{"status":"ok","timestamp":1664039391438,"user_tz":300,"elapsed":98,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# this function gets three words (trigram) in parameter and search and returns fourth word from fourgram distribution\n","def get_word_from_fourgram(first_word, second_word, third_word):\n","  freq_dist_trigram_tuple = cfd_fourgram[(first_word, second_word, third_word)]     # get the fourgram tuple from the trigram word\n","  next_word = get_word_from_unigram(freq_dist_trigram_tuple)  # get a word from frequency distribution of fourgram tuple (fourgram tuple is like a unigram)\n","  return next_word"],"metadata":{"id":"hhZ4YZfPF6el","executionInfo":{"status":"ok","timestamp":1664039391438,"user_tz":300,"elapsed":1,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# Generating 5 fourgram sentences of 10 words each\n","print(\"Fourgram sentences: \")\n","for i in range(1,6):\n","  first_word = get_word_from_unigram(freq_dist_doc)   # get first word from initial document distribution (unigram)\n","  sentence.append(first_word)\n","  second_word = get_word_from_bigram(first_word)\n","  sentence.append(second_word)\n","  third_word = get_word_from_trigram(first_word, second_word)\n","  sentence.append(third_word)\n","  for j in range(7):      # iterate 7 times for rest 7 words\n","    next_word = get_word_from_fourgram(first_word, second_word, third_word)\n","    sentence.append(next_word)\n","    first_word = second_word    # update first_word with second_word for the next iteration        \n","    second_word = third_word    # update second_word with third_word for the next iteration            \n","    third_word = next_word    # update third_word with next_word for the next iteration    \n","  fourgrams_sentence = ' '.join(map(str, sentence))\n","  print(f'Sentence {i} : {fourgrams_sentence}') \n","  sentence = []"],"metadata":{"id":"DkzmbccQGIuv","executionInfo":{"status":"ok","timestamp":1664043612502,"user_tz":300,"elapsed":277,"user":{"displayName":"Blink Drive","userId":"10872384013391211803"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d36fbccc-83e3-448a-ad56-2adbbda490a7"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["Fourgram sentences: \n","Sentence 1 : al. adopts a credibility measurement model related to time factors,\n","Sentence 2 : blockchain in digital finance At present, there are not many\n","Sentence 3 : from being fully released, it has received more and more\n","Sentence 4 : As said previously, no works perform a massive analysis for\n","Sentence 5 : reduce costs associated with the bargaining practice. Nevertheless, developers donâ€™t\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Yt-V1ArXuneD"},"execution_count":null,"outputs":[]}]}